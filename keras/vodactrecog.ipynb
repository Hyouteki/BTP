{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://youtu.be/QmtSkq3DYko?si=6VzZc_NH5glCPi0m\n",
    "- https://learnopencv.com/introduction-to-video-classification-and-human-activity-recognition/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# for downloading youtube vod for training/testing\n",
    "%pip install pafy youtube-dl moviepy\n",
    "%pip install pydot graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pafy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from cv2 import (\n",
    "    VideoCapture, \n",
    "    cvtColor, \n",
    "    COLOR_BGR2RGB,\n",
    "    putText,\n",
    "    FONT_HERSHEY_SIMPLEX,\n",
    "    CAP_PROP_FRAME_COUNT,\n",
    "    CAP_PROP_POS_FRAMES,\n",
    "    resize,\n",
    ")\n",
    "from numpy import asarray, array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to make results consistent on every execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 27\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downloading and extracting UCF50 dataset<br>\n",
    "source: https://www.crcv.ucf.edu/data/UCF50.rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# !wget --no-check-certificate https://www.crcv.ucf.edu/data/UCF50.rar\n",
    "\n",
    "# uncomment this to unrar the rar dataset file \\\n",
    "# or use some unpacking software like 7-ZIP like I did\n",
    "# !unrar x UCF50.rar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualizing the dataset<br>\n",
    "not necessary to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "allClassNames = listdir(\"UCF50\")\n",
    "print(allClassNames)\n",
    "samplesInEachClass = [len(listdir(join(\"UCF50\", i))) for i in allClassNames]\n",
    "print(samplesInEachClass)\n",
    "\n",
    "for i in range(len(allClassNames)):\n",
    "    allVideosInClass = listdir(join(\"UCF50\", allClassNames[i]))\n",
    "    randomSelectedVideo = random.choice(allVideosInClass)\n",
    "    videoReader = VideoCapture(join(\n",
    "        \"UCF50\", allClassNames[i], randomSelectedVideo\n",
    "    ))\n",
    "    _, bgrFrame = videoReader.read()\n",
    "    videoReader.release()\n",
    "    rgbFrame = cvtColor(bgrFrame, COLOR_BGR2RGB)\n",
    "    putText(\n",
    "        rgbFrame, \n",
    "        allClassNames[i], \n",
    "        (10, 30), \n",
    "        FONT_HERSHEY_SIMPLEX, \n",
    "        1, \n",
    "        (255, 255, 255), \n",
    "        2\n",
    "    )\n",
    "    plt.subplot(5, 4, i+1)\n",
    "    plt.imshow(rgbFrame)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 64\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_DIMENSION = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "SEQUENCE_LENGTH = 20\n",
    "DATASET_DIR = \"UCF50\"\n",
    "CLASSES = [\"BenchPress\", \"CleanAndJerk\", \"Diving\", \"BreastStroke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frameExtraction(videoPath):\n",
    "    frames = []\n",
    "    videoReader = VideoCapture(videoPath)\n",
    "    frameCount = int(videoReader.get(CAP_PROP_FRAME_COUNT))\n",
    "    skipFrameWindow = max(int(frameCount / SEQUENCE_LENGTH), 1)\n",
    "    for i in range(SEQUENCE_LENGTH):\n",
    "        videoReader.set(CAP_PROP_POS_FRAMES, i * skipFrameWindow)\n",
    "        success, frame = videoReader.read()\n",
    "        if not success:\n",
    "            break\n",
    "        frames.append(resize(frame, IMAGE_DIMENSION) / 255)\n",
    "    videoReader.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetCreation():\n",
    "    features = []\n",
    "    labels = []\n",
    "    videoFilePaths = []\n",
    "    for classId, className in enumerate(CLASSES):\n",
    "        print(f\"Extracting Data of Class: {className}\")\n",
    "        files = listdir(join(DATASET_DIR, className))\n",
    "        for file in files:\n",
    "            videoFilePath = join(DATASET_DIR, className, file)\n",
    "            frames = frameExtraction(videoFilePath)\n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    "                features.append(frames)\n",
    "                labels.append(classId)\n",
    "                videoFilePaths.append(videoFilePath)\n",
    "    features = asarray(features)\n",
    "    labels = array(labels)\n",
    "    return features, labels, videoFilePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, videoFilePaths = datasetCreation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotEncodedLabels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresTrain, featuresTest, labelsTrain, labelsTest = train_test_split(\n",
    "    features, \n",
    "    oneHotEncodedLabels, \n",
    "    test_size=0.2, \n",
    "    shuffle=True,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelArchitecture():\n",
    "    model = Sequential([\n",
    "        ConvLSTM2D(\n",
    "            filters=4, \n",
    "            kernel_size=(3, 3), \n",
    "            activation=\"tanh\",\n",
    "            data_format = \"channels_last\",\n",
    "            recurrent_dropout=0.2,\n",
    "            return_sequences=True, \n",
    "            input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)\n",
    "        ),\n",
    "        MaxPooling3D(\n",
    "            pool_size=(1, 2, 2), \n",
    "            padding='same', \n",
    "            data_format=\"channels_last\"\n",
    "        ),\n",
    "        TimeDistributed(Dropout(0.2)),\n",
    "        ConvLSTM2D(\n",
    "            filters=8, \n",
    "            kernel_size=(3, 3), \n",
    "            activation=\"tanh\",\n",
    "            data_format = \"channels_last\",\n",
    "            recurrent_dropout=0.2,\n",
    "            return_sequences=True\n",
    "        ),\n",
    "        MaxPooling3D(\n",
    "            pool_size=(1, 2, 2), \n",
    "            padding='same', \n",
    "            data_format=\"channels_last\"\n",
    "        ),\n",
    "        TimeDistributed(Dropout(0.2)),\n",
    "        ConvLSTM2D(\n",
    "            filters=14, \n",
    "            kernel_size=(3, 3), \n",
    "            activation=\"tanh\",\n",
    "            data_format = \"channels_last\",\n",
    "            recurrent_dropout=0.2,\n",
    "            return_sequences=True\n",
    "        ),\n",
    "        MaxPooling3D(\n",
    "            pool_size=(1, 2, 2), \n",
    "            padding='same', \n",
    "            data_format=\"channels_last\"\n",
    "        ),\n",
    "        TimeDistributed(Dropout(0.2)),\n",
    "        ConvLSTM2D(\n",
    "            filters=16, \n",
    "            kernel_size=(3, 3), \n",
    "            activation=\"tanh\",\n",
    "            data_format = \"channels_last\",\n",
    "            recurrent_dropout=0.2,\n",
    "            return_sequences=True\n",
    "        ),\n",
    "        MaxPooling3D(\n",
    "            pool_size=(1, 2, 2), \n",
    "            padding='same', \n",
    "            data_format=\"channels_last\"\n",
    "        ),\n",
    "        Flatten(),\n",
    "        Dense(len(CLASSES), activation=\"softmax\")\n",
    "    ])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModelArchitecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStoppingCallback = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "modelTrainingHistory = model.fit(\n",
    "    x=featuresTrain, \n",
    "    y=labelsTrain, \n",
    "    epochs=7, \n",
    "    batch_size=4, \n",
    "    shuffle=True, \n",
    "    validation_split=0.2, \n",
    "    callbacks = [earlyStoppingCallback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(modelTrainingHistory, metricName1, metricName2, plotName):\n",
    "    metricValue1 = modelTrainingHistory.history[metricName1]\n",
    "    metricValue2 = modelTrainingHistory.history[metricName2]\n",
    "    epochs = range(len(metricValue1))\n",
    "    plt.plot(epochs, metricValue1, 'blue', label=metricName1)\n",
    "    plt.plot(epochs, metricValue2, 'red', label=metricName2)\n",
    "    plt.title(str(plotName))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(modelTrainingHistory, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{DATASET_DIR}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(featuresTest, labelsTest)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictVideo(videoPath):\n",
    "    frames = frameExtraction(videoPath)\n",
    "    confidences = model.predict(asarray([frames]))\n",
    "    i = 0\n",
    "    confidence = confidences[i]\n",
    "    for j in range(1, len(confidences)):\n",
    "        if j > confidence:\n",
    "            confidence = confidences[j]\n",
    "            i = j\n",
    "    return CLASSES[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictVideo(r\"UCF50/BenchPress/v_BenchPress_g01_c01.avi\")\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
